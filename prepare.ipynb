{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QSa4_IBmK19f"
      },
      "source": [
        "# Import Necessary Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_uGb9GTvrQWh",
        "outputId": "0712c9dc-43e4-4011-8a80-331726212ca1"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to\n",
            "[nltk_data]     C:\\Users\\USER\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to\n",
            "[nltk_data]     C:\\Users\\USER\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to\n",
            "[nltk_data]     C:\\Users\\USER\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "import os\n",
        "import re\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from nltk.tokenize import word_tokenize\n",
        "import nltk\n",
        "\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dWp8BIJuK6WV"
      },
      "source": [
        "# Mount Google drive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NzQR2mDbiLo8",
        "outputId": "b03bcbea-0df2-4779-ec33-f393a2f8c7cb"
      },
      "outputs": [],
      "source": [
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WPa8uLrTLAXe"
      },
      "source": [
        "# Define Necessary Functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "gPYfeYaprQWj"
      },
      "outputs": [],
      "source": [
        "# Function to load data from a given file path\n",
        "def load_data(file_path):\n",
        "    data = pd.read_csv(file_path)\n",
        "    return data\n",
        "\n",
        "# Function to preprocess the data\n",
        "def preprocess_data(data):\n",
        "    # Lowercasing\n",
        "    data['text'] = data['text'].apply(lambda x: x.lower())\n",
        "    # Tokenization\n",
        "    data['text'] = data['text'].apply(lambda x: word_tokenize(x))\n",
        "    # Removing stopwords\n",
        "    stop_words = set(stopwords.words('english'))\n",
        "    data['text'] = data['text'].apply(lambda x: [word for word in x if word not in stop_words])\n",
        "    # Lemmatization\n",
        "    lemmatizer = WordNetLemmatizer()\n",
        "    data['text'] = data['text'].apply(lambda x: [lemmatizer.lemmatize(word) for word in x])\n",
        "    # Joining tokens back to string\n",
        "    data['text'] = data['text'].apply(lambda x: ' '.join(x))\n",
        "    return data\n",
        "\n",
        "# Function to split the data into train/validation/test sets\n",
        "def split_data(data, r_state, test_size=0.2, val_size=0.25):\n",
        "    # Splitting data into train and temp (temp will be further split into validation and test)\n",
        "    train_data, temp_data = train_test_split(data, test_size=test_size, random_state=r_state)\n",
        "    # Splitting temp_data into validation and test\n",
        "    validation_data, test_data = train_test_split(temp_data, test_size=val_size, random_state=r_state)\n",
        "    return train_data, validation_data, test_data\n",
        "\n",
        "\n",
        "\n",
        "# Function to store the splits at train.csv/validation.csv/test.csv\n",
        "def store_splits(train_data, validation_data, test_data, output_path):\n",
        "    train_data.to_csv(output_path + 'train.csv', index=False)\n",
        "    validation_data.to_csv(output_path + 'validation.csv', index=False)\n",
        "    test_data.to_csv(output_path + 'test.csv', index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GCI47QVhL-C8"
      },
      "source": [
        "# Load data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "wj5USMyCwYFA"
      },
      "outputs": [],
      "source": [
        "file_path = r'Data/emails.csv'  # Update with the actual path\n",
        "data = load_data(file_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tv9tb9W6MC-d"
      },
      "source": [
        "\n",
        "# Preprocess data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "lkIEfXQ7weUV"
      },
      "outputs": [],
      "source": [
        "processed_data= preprocess_data(data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rhoPGukFMHAP"
      },
      "source": [
        "\n",
        "# Split data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "4AI2UUY_wYFB"
      },
      "outputs": [],
      "source": [
        "train_data, validation_data, test_data = split_data(processed_data,r_state=121, test_size=0.2, val_size=0.25)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bfYopydCMIlK"
      },
      "source": [
        "# Store Splited Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "ZB89-U1exmzJ"
      },
      "outputs": [],
      "source": [
        "store_splits(train_data, validation_data, test_data, output_path=r'Data/')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "wJk2Km1vxtpv"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [],
      "source": [
        "import dvc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Initialized DVC repository.\n",
            "\n",
            "You can now commit the changes to git.\n",
            "\n",
            "+---------------------------------------------------------------------+\n",
            "|                                                                     |\n",
            "|        DVC has enabled anonymous aggregate usage analytics.         |\n",
            "|     Read the analytics documentation (and how to opt-out) here:     |\n",
            "|             <https://dvc.org/doc/user-guide/analytics>              |\n",
            "|                                                                     |\n",
            "+---------------------------------------------------------------------+\n",
            "\n",
            "What's next?"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "------------\n",
            "- Check out the documentation: <https://dvc.org/doc>\n",
            "- Get help and share ideas: <https://dvc.org/chat>\n",
            "- Star us on GitHub: <https://github.com/iterative/dvc>\n"
          ]
        }
      ],
      "source": [
        "!dvc init"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Adding all the 3 splitted csv files to dvc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "fatal: pathspec 'Data/train.csv' did not match any files\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "On branch main\n",
            "Your branch is up to date with 'origin/main'.\n",
            "\n",
            "Changes not staged for commit:\n",
            "  (use \"git add/rm <file>...\" to update what will be committed)\n",
            "  (use \"git restore <file>...\" to discard changes in working directory)\n",
            "\tdeleted:    .gitignore\n",
            "\tdeleted:    emails.csv\n",
            "\tmodified:   prepare.ipynb\n",
            "\tdeleted:    test.csv.dvc\n",
            "\tdeleted:    train.csv.dvc\n",
            "\tdeleted:    validation.csv.dvc\n",
            "\n",
            "Untracked files:\n",
            "  (use \"git add <file>...\" to include in what will be committed)\n",
            "\tData/\n",
            "\tmlruns/\n",
            "\tprep_dvc.ipynb\n",
            "\tprepare_SB.ipynb\n",
            "\ttrain_mlflow.ipynb\n",
            "\n",
            "no changes added to commit (use \"git add\" and/or \"git commit -a\")\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "fatal: pathspec 'Data/validation.csv' did not match any files\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "On branch main\n",
            "Your branch is up to date with 'origin/main'.\n",
            "\n",
            "Changes not staged for commit:\n",
            "  (use \"git add/rm <file>...\" to update what will be committed)\n",
            "  (use \"git restore <file>...\" to discard changes in working directory)\n",
            "\tdeleted:    .gitignore\n",
            "\tdeleted:    emails.csv\n",
            "\tmodified:   prepare.ipynb\n",
            "\tdeleted:    test.csv.dvc\n",
            "\tdeleted:    train.csv.dvc\n",
            "\tdeleted:    validation.csv.dvc\n",
            "\n",
            "Untracked files:\n",
            "  (use \"git add <file>...\" to include in what will be committed)\n",
            "\tData/\n",
            "\tmlruns/\n",
            "\tprep_dvc.ipynb\n",
            "\tprepare_SB.ipynb\n",
            "\ttrain_mlflow.ipynb\n",
            "\n",
            "no changes added to commit (use \"git add\" and/or \"git commit -a\")\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "fatal: pathspec 'Data/test.csv' did not match any files\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "On branch main\n",
            "Your branch is up to date with 'origin/main'.\n",
            "\n",
            "Changes not staged for commit:\n",
            "  (use \"git add/rm <file>...\" to update what will be committed)\n",
            "  (use \"git restore <file>...\" to discard changes in working directory)\n",
            "\tdeleted:    .gitignore\n",
            "\tdeleted:    emails.csv\n",
            "\tmodified:   prepare.ipynb\n",
            "\tdeleted:    test.csv.dvc\n",
            "\tdeleted:    train.csv.dvc\n",
            "\tdeleted:    validation.csv.dvc\n",
            "\n",
            "Untracked files:\n",
            "  (use \"git add <file>...\" to include in what will be committed)\n",
            "\tData/\n",
            "\tmlruns/\n",
            "\tprep_dvc.ipynb\n",
            "\tprepare_SB.ipynb\n",
            "\ttrain_mlflow.ipynb\n",
            "\n",
            "no changes added to commit (use \"git add\" and/or \"git commit -a\")\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "⠋ Checking graph"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "To track the changes with git, run:"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\tgit add 'Data\\.gitignore' 'Data\\train.csv.dvc'\n",
            "\n",
            "To enable auto staging, run:\n",
            "\n",
            "\tdvc config core.autostage true\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "⠋ Checking graph"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "To track the changes with git, run:"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\tgit add 'Data\\validation.csv.dvc' 'Data\\.gitignore'\n",
            "\n",
            "To enable auto staging, run:\n",
            "\n",
            "\tdvc config core.autostage true\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "⠋ Checking graph"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "To track the changes with git, run:"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\tgit add 'Data\\.gitignore' 'Data\\test.csv.dvc'\n",
            "\n",
            "To enable auto staging, run:\n",
            "\n",
            "\tdvc config core.autostage true\n"
          ]
        }
      ],
      "source": [
        "!git rm -r --cached Data/train.csv\n",
        "!git commit -m \"stop tracking train.csv\"\n",
        "!git rm -r --cached Data/validation.csv\n",
        "!git commit -m \"stop tracking validation.csv\"\n",
        "!git rm -r --cached Data/test.csv\n",
        "!git commit -m \"stop tracking test.csv\"\n",
        "\n",
        "!dvc add Data/train.csv\n",
        "!dvc add Data/validation.csv\n",
        "!dvc add Data/test.csv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [],
      "source": [
        "!dvc config core.autostage true"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Adding google drive folder as a remote data storage"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Setting 'myremote_4' as a default remote.\n"
          ]
        }
      ],
      "source": [
        "!dvc remote add --default myremote_4 gdrive://14FcFV3GhBnOIiSWJAKgCglVlrAtVXxqp"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [],
      "source": [
        "!dvc remote modify myremote_4 gdrive_acknowledge_abuse true"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Pushing dvc tracked files to remote storage"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "3 files pushed\n"
          ]
        }
      ],
      "source": [
        "!dvc push"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Data and pipelines are up to date.\n"
          ]
        }
      ],
      "source": [
        "!dvc status"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Everything is up to date.\n"
          ]
        }
      ],
      "source": [
        "!dvc push"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Checkout for the different versions of the data splitting"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "commit 7953ecbdfc9277f957f0c62c95485562efadfb6c\n",
            "Author: akashdas2110 <iamakash476@gmail.com>\n",
            "Date:   Sun Feb 18 18:44:18 2024 +0530\n",
            "\n",
            "    stop tracking train.csv\n",
            "\n",
            "commit 10f8a696a6cd61f209b1e167a46129ac2e0ae1d1\n",
            "Author: akashdas2110 <iamakash476@gmail.com>\n",
            "Date:   Sun Feb 18 18:20:31 2024 +0530\n",
            "\n",
            "    stop tracking test.csv\n",
            "\n",
            "commit 9bcdb7c4f409b89876e164f66e8614a3f6d0f262\n",
            "Author: akashdas2110 <iamakash476@gmail.com>\n",
            "Date:   Sun Feb 18 18:20:31 2024 +0530\n",
            "\n",
            "    stop tracking validation.csv\n",
            "\n",
            "commit 9528539ada14ae2a3dc538d23cac849b9eee24de\n",
            "Author: akashdas2110 <iamakash476@gmail.com>\n",
            "Date:   Sun Feb 18 18:20:30 2024 +0530\n",
            "\n",
            "    stop tracking train.csv\n",
            "\n",
            "commit 3305a71763c14a67ffda9f6c26eb4287ad9d671d"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Author: akashdas2110 <iamakash476@gmail.com>\n",
            "Date:   Sun Feb 18 18:14:47 2024 +0530\n",
            "\n",
            "    stop tracking train.csv\n",
            "\n",
            "commit 4328bb467eef37b7644efcc24e123e6cd64a9a87\n",
            "Author: akashdas2110 <iamakash476@gmail.com>\n",
            "Date:   Sat Feb 17 23:53:57 2024 +0530\n",
            "\n",
            "    stop tracking validation.csv\n",
            "\n",
            "commit 698a4fdc086ab6e15135efc36625083d321f3b23\n",
            "Author: akashdas2110 <iamakash476@gmail.com>\n",
            "Date:   Sat Feb 17 14:54:02 2024 +0530\n",
            "\n",
            "    Assignment 2 Updates\n",
            "\n",
            "commit bed73835f10b538ea57c1cffcd002be4637d4afc\n",
            "Author: akashdas2110 <iamakash476@gmail.com>\n",
            "Date:   Sat Feb 17 14:46:24 2024 +0530\n",
            "\n",
            "    Assignment 2 Updates\n",
            "\n",
            "commit a9c739d3e4422cd78c2a7f23416f3745d299304e\n",
            "Author: akashdas2110 <iamakash476@gmail.com>\n",
            "Date:   Sat Feb 17 14:43:46 2024 +0530\n",
            "\n",
            "    Update\n",
            "\n",
            "commit e990de5bf6a61e96b1e9caaf5911d8377b7aa95f\n",
            "Merge: fbac1f5 0b7478d\n",
            "Author: akashdas2110 <112683602+akashdas2110@users.noreply.github.com>\n",
            "Date:   Sat Feb 17 14:35:20 2024 +0530\n",
            "\n",
            "    Merge pull request #1 from akashdas2110/akashdas2110-patch-1\n",
            "    \n",
            "    ass_2\n",
            "\n",
            "commit 0b7478d8c6b4ca9b1908e115c496c86515128648\n",
            "Author: akashdas2110 <112683602+akashdas2110@users.noreply.github.com>\n",
            "Date:   Sat Feb 17 14:34:46 2024 +0530\n",
            "\n",
            "    ass_2\n",
            "\n",
            "commit fbac1f5a0a02afe132bed3cbc293ec2bde2d40f9\n",
            "Author: akashdas2110 <112683602+akashdas2110@users.noreply.github.com>\n",
            "Date:   Sat Feb 17 14:34:11 2024 +0530\n",
            "\n",
            "    ass 2\n",
            "\n",
            "commit 3c3d0854553070af86bce525d8f7c72b635a720f\n",
            "Author: akashdas2110 <112683602+akashdas2110@users.noreply.github.com>\n",
            "Date:   Sat Feb 17 14:33:03 2024 +0530\n",
            "\n",
            "    Assignment 2 uploads\n",
            "\n",
            "commit aa79ff3d462e7ba4f98ba70c33e67206af1e74e0\n",
            "Author: akashdas2110 <iamakash476@gmail.com>\n",
            "Date:   Sat Feb 17 12:20:22 2024 +0530\n",
            "\n",
            "    check\n",
            "\n",
            "commit 730768a3c8846f980639baee06b10d827d04d666\n",
            "Author: akashdas2110 <112683602+akashdas2110@users.noreply.github.com>\n",
            "Date:   Tue Feb 13 16:11:01 2024 +0530\n",
            "\n",
            "    Add files via upload\n"
          ]
        }
      ],
      "source": [
        "!git log"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Checkout for 1st version"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {},
      "outputs": [],
      "source": [
        "# !git checkout fbac1f5a0a02afe132bed3cbc293ec2bde2d40f9 "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {},
      "outputs": [],
      "source": [
        "!dvc checkout Data/train.csv.dvc\n",
        "!dvc checkout Data/test.csv.dvc\n",
        "!dvc checkout Data/validation.csv.dvc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Everything up-to-date\n"
          ]
        }
      ],
      "source": [
        "!git push"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "# Split data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {},
      "outputs": [],
      "source": [
        "train_data_2, validation_data_2, test_data_2 = split_data(processed_data,r_state=476, test_size=0.2, val_size=0.25)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Store Splited Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {},
      "outputs": [],
      "source": [
        "store_splits(train_data_2, validation_data_2, test_data_2, output_path=r'Data_2/')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {},
      "outputs": [],
      "source": [
        "import dvc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {},
      "outputs": [],
      "source": [
        "# !dvc init"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Adding all the 3 splitted csv files to dvc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "fatal: pathspec 'Data_2/train.csv' did not match any files\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "On branch main\n",
            "Your branch is up to date with 'origin/main'.\n",
            "\n",
            "Changes not staged for commit:\n",
            "  (use \"git add/rm <file>...\" to update what will be committed)\n",
            "  (use \"git restore <file>...\" to discard changes in working directory)\n",
            "\tmodified:   .dvc/config\n",
            "\tdeleted:    .gitignore\n",
            "\tdeleted:    emails.csv\n",
            "\tmodified:   prepare.ipynb\n",
            "\tdeleted:    test.csv.dvc\n",
            "\tdeleted:    train.csv.dvc\n",
            "\tdeleted:    validation.csv.dvc\n",
            "\n",
            "Untracked files:\n",
            "  (use \"git add <file>...\" to include in what will be committed)\n",
            "\tData/\n",
            "\tData_2/\n",
            "\tmlruns/\n",
            "\tprep_dvc.ipynb\n",
            "\tprepare_SB.ipynb\n",
            "\ttrain_mlflow.ipynb\n",
            "\n",
            "no changes added to commit (use \"git add\" and/or \"git commit -a\")\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "fatal: pathspec 'Data_2/validation.csv' did not match any files\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "On branch main\n",
            "Your branch is up to date with 'origin/main'.\n",
            "\n",
            "Changes not staged for commit:\n",
            "  (use \"git add/rm <file>...\" to update what will be committed)\n",
            "  (use \"git restore <file>...\" to discard changes in working directory)\n",
            "\tmodified:   .dvc/config\n",
            "\tdeleted:    .gitignore\n",
            "\tdeleted:    emails.csv\n",
            "\tmodified:   prepare.ipynb\n",
            "\tdeleted:    test.csv.dvc\n",
            "\tdeleted:    train.csv.dvc\n",
            "\tdeleted:    validation.csv.dvc\n",
            "\n",
            "Untracked files:\n",
            "  (use \"git add <file>...\" to include in what will be committed)\n",
            "\tData/\n",
            "\tData_2/\n",
            "\tmlruns/\n",
            "\tprep_dvc.ipynb\n",
            "\tprepare_SB.ipynb\n",
            "\ttrain_mlflow.ipynb\n",
            "\n",
            "no changes added to commit (use \"git add\" and/or \"git commit -a\")\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "fatal: pathspec 'Data_2/test.csv' did not match any files\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "On branch main\n",
            "Your branch is up to date with 'origin/main'.\n",
            "\n",
            "Changes not staged for commit:\n",
            "  (use \"git add/rm <file>...\" to update what will be committed)\n",
            "  (use \"git restore <file>...\" to discard changes in working directory)\n",
            "\tmodified:   .dvc/config\n",
            "\tdeleted:    .gitignore\n",
            "\tdeleted:    emails.csv\n",
            "\tmodified:   prepare.ipynb\n",
            "\tdeleted:    test.csv.dvc\n",
            "\tdeleted:    train.csv.dvc\n",
            "\tdeleted:    validation.csv.dvc\n",
            "\n",
            "Untracked files:\n",
            "  (use \"git add <file>...\" to include in what will be committed)\n",
            "\tData/\n",
            "\tData_2/\n",
            "\tmlruns/\n",
            "\tprep_dvc.ipynb\n",
            "\tprepare_SB.ipynb\n",
            "\ttrain_mlflow.ipynb\n",
            "\n",
            "no changes added to commit (use \"git add\" and/or \"git commit -a\")\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "⠋ Checking graph\n",
            "\n",
            "⠋ Checking graph\n",
            "\n",
            "⠋ Checking graph\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!git rm -r --cached Data_2/train.csv\n",
        "!git commit -m \"stop tracking train.csv\"\n",
        "!git rm -r --cached Data_2/validation.csv\n",
        "!git commit -m \"stop tracking validation.csv\"\n",
        "!git rm -r --cached Data_2/test.csv\n",
        "!git commit -m \"stop tracking test.csv\"\n",
        "\n",
        "!dvc add Data_2/train.csv\n",
        "!dvc add Data_2/validation.csv\n",
        "!dvc add Data_2/test.csv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {},
      "outputs": [],
      "source": [
        "!dvc config core.autostage true"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Adding google drive folder as a remote data storage"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {},
      "outputs": [],
      "source": [
        "# !dvc remote add --default myremote_4 gdrive://14FcFV3GhBnOIiSWJAKgCglVlrAtVXxqp"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {},
      "outputs": [],
      "source": [
        "# !dvc remote modify myremote_4 gdrive_acknowledge_abuse true"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Pushing dvc tracked files to remote storage"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "3 files pushed\n"
          ]
        }
      ],
      "source": [
        "!dvc push"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Data and pipelines are up to date.\n"
          ]
        }
      ],
      "source": [
        "!dvc status"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Everything is up to date.\n"
          ]
        }
      ],
      "source": [
        "!dvc push"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Checkout for the different versions of the data splitting"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "commit 7953ecbdfc9277f957f0c62c95485562efadfb6c\n",
            "Author: akashdas2110 <iamakash476@gmail.com>\n",
            "Date:   Sun Feb 18 18:44:18 2024 +0530\n",
            "\n",
            "    stop tracking train.csv\n",
            "\n",
            "commit 10f8a696a6cd61f209b1e167a46129ac2e0ae1d1\n",
            "Author: akashdas2110 <iamakash476@gmail.com>\n",
            "Date:   Sun Feb 18 18:20:31 2024 +0530\n",
            "\n",
            "    stop tracking test.csv\n",
            "\n",
            "commit 9bcdb7c4f409b89876e164f66e8614a3f6d0f262\n",
            "Author: akashdas2110 <iamakash476@gmail.com>\n",
            "Date:   Sun Feb 18 18:20:31 2024 +0530\n",
            "\n",
            "    stop tracking validation.csv\n",
            "\n",
            "commit 9528539ada14ae2a3dc538d23cac849b9eee24de\n",
            "Author: akashdas2110 <iamakash476@gmail.com>\n",
            "Date:   Sun Feb 18 18:20:30 2024 +0530\n",
            "\n",
            "    stop tracking train.csv\n",
            "\n",
            "commit 3305a71763c14a67ffda9f6c26eb4287ad9d671d\n",
            "Author: akashdas2110 <iamakash476@gmail.com>\n",
            "Date:   Sun Feb 18 18:14:47 2024 +0530\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "    stop tracking train.csv\n",
            "\n",
            "commit 4328bb467eef37b7644efcc24e123e6cd64a9a87\n",
            "Author: akashdas2110 <iamakash476@gmail.com>\n",
            "Date:   Sat Feb 17 23:53:57 2024 +0530\n",
            "\n",
            "    stop tracking validation.csv\n",
            "\n",
            "commit 698a4fdc086ab6e15135efc36625083d321f3b23\n",
            "Author: akashdas2110 <iamakash476@gmail.com>\n",
            "Date:   Sat Feb 17 14:54:02 2024 +0530\n",
            "\n",
            "    Assignment 2 Updates\n",
            "\n",
            "commit bed73835f10b538ea57c1cffcd002be4637d4afc\n",
            "Author: akashdas2110 <iamakash476@gmail.com>\n",
            "Date:   Sat Feb 17 14:46:24 2024 +0530\n",
            "\n",
            "    Assignment 2 Updates\n",
            "\n",
            "commit a9c739d3e4422cd78c2a7f23416f3745d299304e\n",
            "Author: akashdas2110 <iamakash476@gmail.com>\n",
            "Date:   Sat Feb 17 14:43:46 2024 +0530\n",
            "\n",
            "    Update\n",
            "\n",
            "commit e990de5bf6a61e96b1e9caaf5911d8377b7aa95f\n",
            "Merge: fbac1f5 0b7478d\n",
            "Author: akashdas2110 <112683602+akashdas2110@users.noreply.github.com>\n",
            "Date:   Sat Feb 17 14:35:20 2024 +0530\n",
            "\n",
            "    Merge pull request #1 from akashdas2110/akashdas2110-patch-1\n",
            "    \n",
            "    ass_2\n",
            "\n",
            "commit 0b7478d8c6b4ca9b1908e115c496c86515128648\n",
            "Author: akashdas2110 <112683602+akashdas2110@users.noreply.github.com>\n",
            "Date:   Sat Feb 17 14:34:46 2024 +0530\n",
            "\n",
            "    ass_2\n",
            "\n",
            "commit fbac1f5a0a02afe132bed3cbc293ec2bde2d40f9\n",
            "Author: akashdas2110 <112683602+akashdas2110@users.noreply.github.com>\n",
            "Date:   Sat Feb 17 14:34:11 2024 +0530\n",
            "\n",
            "    ass 2\n",
            "\n",
            "commit 3c3d0854553070af86bce525d8f7c72b635a720f\n",
            "Author: akashdas2110 <112683602+akashdas2110@users.noreply.github.com>\n",
            "Date:   Sat Feb 17 14:33:03 2024 +0530\n",
            "\n",
            "    Assignment 2 uploads\n",
            "\n",
            "commit aa79ff3d462e7ba4f98ba70c33e67206af1e74e0\n",
            "Author: akashdas2110 <iamakash476@gmail.com>\n",
            "Date:   Sat Feb 17 12:20:22 2024 +0530\n",
            "\n",
            "    check\n",
            "\n",
            "commit 730768a3c8846f980639baee06b10d827d04d666\n",
            "Author: akashdas2110 <112683602+akashdas2110@users.noreply.github.com>\n",
            "Date:   Tue Feb 13 16:11:01 2024 +0530\n",
            "\n",
            "    Add files via upload\n"
          ]
        }
      ],
      "source": [
        "!git log"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Checkout for 1st version"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {},
      "outputs": [],
      "source": [
        "# !git checkout fbac1f5a0a02afe132bed3cbc293ec2bde2d40f9 "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {},
      "outputs": [],
      "source": [
        "!dvc checkout Data_2/train.csv.dvc\n",
        "!dvc checkout Data_2/test.csv.dvc\n",
        "!dvc checkout Data_2/validation.csv.dvc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Everything up-to-date\n"
          ]
        }
      ],
      "source": [
        "!git push"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "commit 7953ecbdfc9277f957f0c62c95485562efadfb6c\n",
            "Author: akashdas2110 <iamakash476@gmail.com>\n",
            "Date:   Sun Feb 18 18:44:18 2024 +0530\n",
            "\n",
            "    stop tracking train.csv\n",
            "\n",
            "commit 10f8a696a6cd61f209b1e167a46129ac2e0ae1d1\n",
            "Author: akashdas2110 <iamakash476@gmail.com>\n",
            "Date:   Sun Feb 18 18:20:31 2024 +0530\n",
            "\n",
            "    stop tracking test.csv\n",
            "\n",
            "commit 9bcdb7c4f409b89876e164f66e8614a3f6d0f262\n",
            "Author: akashdas2110 <iamakash476@gmail.com>\n",
            "Date:   Sun Feb 18 18:20:31 2024 +0530\n",
            "\n",
            "    stop tracking validation.csv\n",
            "\n",
            "commit 9528539ada14ae2a3dc538d23cac849b9eee24de\n",
            "Author: akashdas2110 <iamakash476@gmail.com>\n",
            "Date:   Sun Feb 18 18:20:30 2024 +0530\n",
            "\n",
            "    stop tracking train.csv\n",
            "\n",
            "commit 3305a71763c14a67ffda9f6c26eb4287ad9d671d"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Author: akashdas2110 <iamakash476@gmail.com>\n",
            "Date:   Sun Feb 18 18:14:47 2024 +0530\n",
            "\n",
            "    stop tracking train.csv\n",
            "\n",
            "commit 4328bb467eef37b7644efcc24e123e6cd64a9a87\n",
            "Author: akashdas2110 <iamakash476@gmail.com>\n",
            "Date:   Sat Feb 17 23:53:57 2024 +0530\n",
            "\n",
            "    stop tracking validation.csv\n",
            "\n",
            "commit 698a4fdc086ab6e15135efc36625083d321f3b23\n",
            "Author: akashdas2110 <iamakash476@gmail.com>\n",
            "Date:   Sat Feb 17 14:54:02 2024 +0530\n",
            "\n",
            "    Assignment 2 Updates\n",
            "\n",
            "commit bed73835f10b538ea57c1cffcd002be4637d4afc\n",
            "Author: akashdas2110 <iamakash476@gmail.com>\n",
            "Date:   Sat Feb 17 14:46:24 2024 +0530\n",
            "\n",
            "    Assignment 2 Updates\n",
            "\n",
            "commit a9c739d3e4422cd78c2a7f23416f3745d299304e\n",
            "Author: akashdas2110 <iamakash476@gmail.com>\n",
            "Date:   Sat Feb 17 14:43:46 2024 +0530\n",
            "\n",
            "    Update\n",
            "\n",
            "commit e990de5bf6a61e96b1e9caaf5911d8377b7aa95f\n",
            "Merge: fbac1f5 0b7478d\n",
            "Author: akashdas2110 <112683602+akashdas2110@users.noreply.github.com>\n",
            "Date:   Sat Feb 17 14:35:20 2024 +0530\n",
            "\n",
            "    Merge pull request #1 from akashdas2110/akashdas2110-patch-1\n",
            "    \n",
            "    ass_2\n",
            "\n",
            "commit 0b7478d8c6b4ca9b1908e115c496c86515128648\n",
            "Author: akashdas2110 <112683602+akashdas2110@users.noreply.github.com>\n",
            "Date:   Sat Feb 17 14:34:46 2024 +0530\n",
            "\n",
            "    ass_2\n",
            "\n",
            "commit fbac1f5a0a02afe132bed3cbc293ec2bde2d40f9\n",
            "Author: akashdas2110 <112683602+akashdas2110@users.noreply.github.com>\n",
            "Date:   Sat Feb 17 14:34:11 2024 +0530\n",
            "\n",
            "    ass 2\n",
            "\n",
            "commit 3c3d0854553070af86bce525d8f7c72b635a720f\n",
            "Author: akashdas2110 <112683602+akashdas2110@users.noreply.github.com>\n",
            "Date:   Sat Feb 17 14:33:03 2024 +0530\n",
            "\n",
            "    Assignment 2 uploads\n",
            "\n",
            "commit aa79ff3d462e7ba4f98ba70c33e67206af1e74e0\n",
            "Author: akashdas2110 <iamakash476@gmail.com>\n",
            "Date:   Sat Feb 17 12:20:22 2024 +0530\n",
            "\n",
            "    check\n",
            "\n",
            "commit 730768a3c8846f980639baee06b10d827d04d666\n",
            "Author: akashdas2110 <112683602+akashdas2110@users.noreply.github.com>\n",
            "Date:   Tue Feb 13 16:11:01 2024 +0530\n",
            "\n",
            "    Add files via upload\n"
          ]
        }
      ],
      "source": [
        "!git log"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
